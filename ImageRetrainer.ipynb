{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import tarfile\n",
    "import re\n",
    "import random\n",
    "import hashlib\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.util import compat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inception_url = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\n",
    "inception_dir_filepath = './inception/'\n",
    "inception_filepath = inception_dir_filepath + 'classify_image_graph_def.pb'\n",
    "train_graph_dir_filepath = './train'\n",
    "input_tensor_name = 'Mul:0'\n",
    "second_last_tensor_name = 'pool_3/_reshape:0'\n",
    "second_last_tensor_size = 2048\n",
    "MAX_NUM_IMAGES_PER_CLASS = 2 ** 27 - 1\n",
    "\n",
    "num_training_steps = 2000\n",
    "train_batch_size = 100\n",
    "eval_step_interval = 10\n",
    "testing_percentage = 20\n",
    "validation_percentage = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, images_dict):\n",
    "        self.images_dict = images_dict\n",
    "        graph = tf.Graph()\n",
    "\n",
    "        with graph.as_default():\n",
    "            with tf.gfile.FastGFile(inception_filepath, 'rb') as f:\n",
    "                graph_def = tf.GraphDef()\n",
    "                graph_def.ParseFromString(f.read())\n",
    "                self.input_tensor, bottleneck_input = tf.import_graph_def(graph_def, name='', return_elements=[input_tensor_name, second_last_tensor_name])\n",
    "\n",
    "        self.session = tf.Session(graph=graph)\n",
    "\n",
    "        with self.session as sess:\n",
    "            self.jpeg_data_tensor, self.decoded_image_tensor = self.add_jpeg_decoding(299, 299, 3, 128, 128)\n",
    "            self.add_final_layer(bottleneck_input, len(self.images_dict.keys()))\n",
    "            self.add_evaluation_step()\n",
    "\n",
    "            self.merged = tf.summary.merge_all()\n",
    "            if not os.path.exists(train_graph_dir_filepath):\n",
    "                os.makedirs(train_graph_dir_filepath)\n",
    "            self.train_writer = tf.summary.FileWriter(train_graph_dir_filepath, graph)\n",
    "\n",
    "            init = tf.global_variables_initializer()\n",
    "            sess.run(init)\n",
    "\n",
    "            self.layer = graph.get_tensor_by_name('conv:0')\n",
    "            for i in graph.get_operations():\n",
    "                print(i.values())\n",
    "\n",
    "            self.train_network(num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def add_jpeg_decoding(self, input_width, input_height, input_depth, input_mean, input_std):\n",
    "        jpeg_data = tf.placeholder(tf.string, name='decode_jpg_input')\n",
    "        decoded_image = tf.image.decode_jpeg(jpeg_data, channels=input_depth)\n",
    "        decoded_image_as_float = tf.cast(decoded_image, dtype=tf.float32)\n",
    "        decoded_image_4d = tf.expand_dims(decoded_image_as_float, 0)\n",
    "        resize_shape = tf.stack([input_height, input_width])\n",
    "        resize_shape_as_int = tf.cast(resize_shape, dtype=tf.int32)\n",
    "        resized_image = tf.image.resize_bilinear(decoded_image_4d,\n",
    "                                               resize_shape_as_int)\n",
    "        offset_image = tf.subtract(resized_image, input_mean)\n",
    "        mul_image = tf.multiply(offset_image, 1.0 / input_std)\n",
    "\n",
    "        return jpeg_data, mul_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def add_final_layer(self, bottleneck_input, class_count):\n",
    "        self.bottleneck_tensor = tf.placeholder_with_default(bottleneck_input, shape=[None, second_last_tensor_size], name='input_placeholder')\n",
    "        self.ground_truth_tensor = tf.placeholder(tf.float32, [None, class_count], name='ground_truth_input')\n",
    "\n",
    "        layer_weights = tf.Variable(tf.truncated_normal([second_last_tensor_size, class_count], stddev=0.001), name='final_weights')\n",
    "        layer_biases = tf.Variable(tf.zeros([class_count]), name='final_biases')\n",
    "\n",
    "        logits = tf.add(tf.matmul(self.bottleneck_tensor, layer_weights), layer_biases)\n",
    "\n",
    "        self.final_tensor = tf.nn.softmax(logits, name='final_result')\n",
    "\n",
    "        with tf.name_scope('cross_entropy'):\n",
    "            cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=self.ground_truth_tensor, logits=logits)\n",
    "            with tf.name_scope('total'):\n",
    "                cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "        tf.summary.scalar('cross_entropy', cross_entropy_mean)\n",
    "\n",
    "        with tf.name_scope('train'):\n",
    "            optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "            self.train_step = optimizer.minimize(cross_entropy_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    '''\n",
    "    Evaluation step is used to evaluate the accuracy of the model\n",
    "    '''\n",
    "    def add_evaluation_step(self):\n",
    "        with tf.name_scope('accuracy'):\n",
    "            with tf.name_scope('correct_prediction'):\n",
    "                self.prediction = tf.argmax(self.final_tensor, 1)\n",
    "                correct_prediction = tf.equal(self.prediction, tf.argmax(self.ground_truth_tensor, 1))\n",
    "            self.evaluation_step = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        tf.summary.scalar('accuracy', self.evaluation_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    '''\n",
    "    This will be used to train the model by randomly fetching a train_batch_size amount of images for num_training_steps\n",
    "    '''\n",
    "    def train_network(self, num_training_steps):\n",
    "        print(\"Starting...\")\n",
    "\n",
    "        for i in range(num_training_steps):\n",
    "            train_bottlenecks, train_ground_truths = self.get_tensors_for_training('training')\n",
    "\n",
    "            train_summary, _ = self.session.run([self.merged, self.train_step], feed_dict={self.bottleneck_tensor: train_bottlenecks, self.ground_truth_tensor: train_ground_truths})\n",
    "            self.train_writer.add_summary(train_summary, i)\n",
    "\n",
    "            if (i % eval_step_interval) == 0:\n",
    "                train_accuracy = self.session.run([self.evaluation_step], feed_dict={self.bottleneck_tensor: train_bottlenecks, self.ground_truth_tensor: train_ground_truths})[0]\n",
    "                print('Step %d: Train accuracy = %.1f%%' % (i, train_accuracy * 100))\n",
    "\n",
    "        test_bottlenecks, test_ground_truths = self.get_tensors_for_testing('testing')\n",
    "        test_accuracy, predictions = self.session.run([self.evaluation_step, self.prediction], feed_dict={\n",
    "            self.bottleneck_tensor: test_bottlenecks, self.ground_truth_tensor: test_ground_truths})\n",
    "        print('Final test accuracy = %.1f%% (N=%d)' % (test_accuracy * 100, len(test_bottlenecks)))\n",
    "\n",
    "        self.getActivations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def get_tensors_for_training(self, category):\n",
    "        class_count = len(self.images_dict.keys())\n",
    "        tensor_inputs, ground_truth_inputs = [], []\n",
    "\n",
    "        for unused_i in range(train_batch_size):\n",
    "            label_index = random.randrange(class_count)\n",
    "            label_name = list(self.images_dict.keys())[label_index]\n",
    "\n",
    "            image_index = random.randrange(MAX_NUM_IMAGES_PER_CLASS + 1)\n",
    "            image_path = self.get_image_path(label_name, image_index, category)\n",
    "            image_data = tf.gfile.FastGFile(image_path, 'rb').read()\n",
    "            tensor_input = self.run_bottleneck_on_image(image_data)\n",
    "\n",
    "            ground_truth_input = np.zeros(class_count, dtype=np.float32)\n",
    "            ground_truth_input[label_index] = 1.0\n",
    "\n",
    "            tensor_inputs.append(tensor_input)\n",
    "            ground_truth_inputs.append(ground_truth_input)\n",
    "\n",
    "        return tensor_inputs, ground_truth_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def get_tensors_for_testing(self, category):\n",
    "        class_count = len(self.images_dict.keys())\n",
    "        bottlenecks, ground_truths = [], []\n",
    "        for label_index, label_name in enumerate(self.images_dict.keys()):\n",
    "            for image_index, image_name in enumerate(self.images_dict[label_name][category]):\n",
    "                image_path = self.get_image_path(label_name, image_index, category)\n",
    "                image_data = tf.gfile.FastGFile(image_path, 'rb').read()\n",
    "                bottleneck = self.run_bottleneck_on_image(image_data)\n",
    "\n",
    "                ground_truth = np.zeros(class_count, dtype=np.float32)\n",
    "                ground_truth[label_index] = 1.0\n",
    "\n",
    "                bottlenecks.append(bottleneck)\n",
    "                ground_truths.append(ground_truth)\n",
    "\n",
    "        return bottlenecks, ground_truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def get_image_path(self, label_name, index, category):\n",
    "        label_lists = self.images_dict[label_name]\n",
    "        category_list = label_lists[category]\n",
    "        mod_index = index % len(category_list)\n",
    "        base_name = category_list[mod_index]\n",
    "        full_path = os.path.join('./dataset', label_name, base_name)\n",
    "        return full_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def run_bottleneck_on_image(self, image_data):\n",
    "        # First decode the JPEG image, resize it, and rescale the pixel values.\n",
    "        resized_input_values = self.session.run(self.decoded_image_tensor, {self.jpeg_data_tensor: image_data})\n",
    "        # Then run it through the recognition network.\n",
    "        bottleneck_values = self.session.run(self.bottleneck_tensor, {self.input_tensor: resized_input_values})\n",
    "        bottleneck_values = np.squeeze(bottleneck_values)\n",
    "        return bottleneck_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def getActivations(self):\n",
    "        image_path = self.get_image_path(list(self.images_dict.keys())[0], 0, 'validation')\n",
    "        image_data = tf.gfile.FastGFile(image_path, 'rb').read()\n",
    "        resized_input_values = self.session.run(self.decoded_image_tensor, {self.jpeg_data_tensor: image_data})\n",
    "\n",
    "        units = self.session.run(self.layer, {self.input_tensor: resized_input_values})\n",
    "        self.plotNNFilter(units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def plotNNFilter(self, units):\n",
    "        filters = units.shape[3]\n",
    "        plt.figure(1, figsize=(20,20))\n",
    "        n_columns = 6\n",
    "        n_rows = math.ceil(filters / n_columns) + 1\n",
    "\n",
    "        for i in range(filters):\n",
    "            plt.subplot(n_rows, n_columns, i+1)\n",
    "            plt.title('Filter ' + str(i))\n",
    "            plt.imshow(units[0,:,:,i], interpolation=\"nearest\", cmap=\"gray\")\n",
    "        plt.savefig('myfig.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Download and initialize the inception model\n",
    "'''\n",
    "def initialize_model(images_dict):\n",
    "    if not os.path.exists(inception_dir_filepath):\n",
    "        urllib.request.urlretrieve(inception_url, inception_url.split('/')[-1])\n",
    "        os.makedirs(inception_dir_filepath)\n",
    "        tarfile.open(inception_url.split('/')[-1], 'r:gz').extractall(inception_dir_filepath)\n",
    "    return NeuralNetwork(images_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Get arrays of training and testing images\n",
    "'''\n",
    "def initialize_images():\n",
    "    images_dict = {}\n",
    "    artist_dirs = [x[0] for i, x in enumerate(os.walk('./dataset')) if i != 0]\n",
    "\n",
    "    for artist_dir in artist_dirs:\n",
    "        artist_name = os.path.basename(artist_dir)\n",
    "        artist_images = filter(lambda f: f.split('.')[-1] in ['jpg', 'jpeg', 'JPG', 'JPEG'], os.listdir(artist_dir))\n",
    "\n",
    "        validation_images, testing_images, training_images = [], [], []\n",
    "\n",
    "        for artist_image in artist_images:\n",
    "            base_name = os.path.basename(artist_image)\n",
    "            hash_name = re.sub(r'_nohash_.*$', '', base_name)\n",
    "            hash_name_hashed = hashlib.sha1(compat.as_bytes(hash_name)).hexdigest()\n",
    "            percentage_hash = ((int(hash_name_hashed, 16) % (MAX_NUM_IMAGES_PER_CLASS + 1)) * (100.0 / MAX_NUM_IMAGES_PER_CLASS))\n",
    "\n",
    "            if percentage_hash < validation_percentage:\n",
    "                validation_images.append(base_name)\n",
    "            elif percentage_hash < (testing_percentage + validation_percentage):\n",
    "                testing_images.append(base_name)\n",
    "            else:\n",
    "                training_images.append(base_name)\n",
    "\n",
    "        images_dict[artist_name] = {\n",
    "            'training': training_images,\n",
    "            'testing': testing_images,\n",
    "            'validation': validation_images\n",
    "        }\n",
    "\n",
    "    return images_dict\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model = initialize_model(initialize_images())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
